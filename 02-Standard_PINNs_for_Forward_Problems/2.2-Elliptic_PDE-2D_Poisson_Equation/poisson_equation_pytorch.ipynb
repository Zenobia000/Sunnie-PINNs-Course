{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2: 2D Poisson Equation - PyTorch Implementation\n",
    "\n",
    "This notebook solves the 2D Poisson equation using pure PyTorch instead of DeepXDE.\n",
    "The Poisson equation is a canonical example of an elliptic PDE.\n",
    "\n",
    "### Problem Definition:\n",
    "- **PDE**: $\\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2} = f(x, y)$\n",
    "- **Source function**: $f(x, y) = -2\\pi^2 \\sin(\\pi x) \\sin(\\pi y)$\n",
    "- **Domain**: $x \\in [-1, 1]$, $y \\in [-1, 1]$\n",
    "- **Boundary Conditions**: $u(x, y) = 0$ on the entire boundary\n",
    "- **Analytical Solution**: $u(x, y) = \\sin(\\pi x) \\sin(\\pi y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import time\n",
    "\n",
    "# Set device and style\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoissonPINN(nn.Module):\n",
    "    \"\"\"Physics-Informed Neural Network for 2D Poisson Equation\"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_dim=50, num_layers=3):\n",
    "        super(PoissonPINN, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(nn.Linear(2, hidden_dim))  # Input: (x, y)\n",
    "        \n",
    "        for _ in range(num_layers):\n",
    "            layers.append(nn.Tanh())\n",
    "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "        \n",
    "        layers.append(nn.Tanh())\n",
    "        layers.append(nn.Linear(hidden_dim, 1))  # Output: u(x,y)\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "        # Initialize weights using Glorot normal\n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_normal_(module.weight)\n",
    "            nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# Create model\n",
    "model = PoissonPINN(hidden_dim=50, num_layers=3).to(device)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Domain Sampling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_domain_points(num_points, device=device):\n",
    "    \"\"\"Sample points from the interior domain [-1,1] × [-1,1]\"\"\"\n",
    "    x = torch.rand(num_points, 1, device=device) * 2 - 1  # x ∈ [-1, 1]\n",
    "    y = torch.rand(num_points, 1, device=device) * 2 - 1  # y ∈ [-1, 1]\n",
    "    return torch.cat([x, y], dim=1)\n",
    "\n",
    "def sample_boundary_points(num_points, device=device):\n",
    "    \"\"\"Sample points from the boundary of [-1,1] × [-1,1]\"\"\"\n",
    "    points_per_side = num_points // 4\n",
    "    \n",
    "    # Bottom boundary: y = -1\n",
    "    x_bottom = torch.rand(points_per_side, 1, device=device) * 2 - 1\n",
    "    y_bottom = torch.full((points_per_side, 1), -1.0, device=device)\n",
    "    bottom = torch.cat([x_bottom, y_bottom], dim=1)\n",
    "    \n",
    "    # Top boundary: y = 1\n",
    "    x_top = torch.rand(points_per_side, 1, device=device) * 2 - 1\n",
    "    y_top = torch.full((points_per_side, 1), 1.0, device=device)\n",
    "    top = torch.cat([x_top, y_top], dim=1)\n",
    "    \n",
    "    # Left boundary: x = -1\n",
    "    x_left = torch.full((points_per_side, 1), -1.0, device=device)\n",
    "    y_left = torch.rand(points_per_side, 1, device=device) * 2 - 1\n",
    "    left = torch.cat([x_left, y_left], dim=1)\n",
    "    \n",
    "    # Right boundary: x = 1\n",
    "    x_right = torch.full((points_per_side, 1), 1.0, device=device)\n",
    "    y_right = torch.rand(points_per_side, 1, device=device) * 2 - 1\n",
    "    right = torch.cat([x_right, y_right], dim=1)\n",
    "    \n",
    "    return torch.cat([bottom, top, left, right], dim=0)\n",
    "\n",
    "# Sample points\n",
    "num_domain = 2500\n",
    "num_boundary = 100\n",
    "\n",
    "domain_points = sample_domain_points(num_domain, device)\n",
    "boundary_points = sample_boundary_points(num_boundary, device)\n",
    "\n",
    "print(f\"Domain points: {domain_points.shape}\")\n",
    "print(f\"Boundary points: {boundary_points.shape}\")\n",
    "\n",
    "# Visualize sampling\n",
    "plt.figure(figsize=(8, 8))\n",
    "domain_np = domain_points.cpu().numpy()\n",
    "boundary_np = boundary_points.cpu().numpy()\n",
    "plt.scatter(domain_np[:500, 0], domain_np[:500, 1], alpha=0.3, s=1, label='Domain', color='blue')\n",
    "plt.scatter(boundary_np[:, 0], boundary_np[:, 1], alpha=0.7, s=10, label='Boundary', color='red')\n",
    "plt.xlim([-1.1, 1.1])\n",
    "plt.ylim([-1.1, 1.1])\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Sampling Points Distribution')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Automatic Differentiation Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_laplacian(u, points):\n",
    "    \"\"\"Compute the Laplacian ∇²u = ∂²u/∂x² + ∂²u/∂y²\n",
    "    \n",
    "    Args:\n",
    "        u: Network output u(x,y)\n",
    "        points: Input points [x, y]\n",
    "    \n",
    "    Returns:\n",
    "        laplacian: ∇²u\n",
    "    \"\"\"\n",
    "    # First derivatives\n",
    "    grad = torch.autograd.grad(\n",
    "        outputs=u,\n",
    "        inputs=points,\n",
    "        grad_outputs=torch.ones_like(u),\n",
    "        create_graph=True,\n",
    "        retain_graph=True\n",
    "    )[0]\n",
    "    \n",
    "    u_x = grad[:, 0:1]  # ∂u/∂x\n",
    "    u_y = grad[:, 1:2]  # ∂u/∂y\n",
    "    \n",
    "    # Second derivatives\n",
    "    u_xx = torch.autograd.grad(\n",
    "        outputs=u_x,\n",
    "        inputs=points,\n",
    "        grad_outputs=torch.ones_like(u_x),\n",
    "        create_graph=True,\n",
    "        retain_graph=True\n",
    "    )[0][:, 0:1]  # ∂²u/∂x²\n",
    "    \n",
    "    u_yy = torch.autograd.grad(\n",
    "        outputs=u_y,\n",
    "        inputs=points,\n",
    "        grad_outputs=torch.ones_like(u_y),\n",
    "        create_graph=True,\n",
    "        retain_graph=True\n",
    "    )[0][:, 1:2]  # ∂²u/∂y²\n",
    "    \n",
    "    # Laplacian\n",
    "    laplacian = u_xx + u_yy\n",
    "    return laplacian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Problem Definition Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_function(points):\n",
    "    \"\"\"Source function: f(x,y) = -2π²sin(πx)sin(πy)\"\"\"\n",
    "    x = points[:, 0:1]\n",
    "    y = points[:, 1:2]\n",
    "    return -2 * np.pi**2 * torch.sin(np.pi * x) * torch.sin(np.pi * y)\n",
    "\n",
    "def analytical_solution(points):\n",
    "    \"\"\"Analytical solution: u(x,y) = sin(πx)sin(πy)\"\"\"\n",
    "    x = points[:, 0:1]\n",
    "    y = points[:, 1:2]\n",
    "    return torch.sin(np.pi * x) * torch.sin(np.pi * y)\n",
    "\n",
    "def boundary_condition(points):\n",
    "    \"\"\"Boundary condition: u = 0 on boundary\"\"\"\n",
    "    return torch.zeros(points.shape[0], 1, device=points.device)\n",
    "\n",
    "# Test functions\n",
    "test_points = torch.tensor([[0.0, 0.0], [0.5, 0.5]], device=device)\n",
    "print(f\"Source at (0,0): {source_function(test_points)[0].item():.6f}\")\n",
    "print(f\"Analytical at (0.5,0.5): {analytical_solution(test_points)[1].item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_losses(model, domain_points, boundary_points):\n",
    "    \"\"\"Compute all loss components for the Poisson equation\"\"\"\n",
    "    \n",
    "    # Enable gradients for domain points\n",
    "    domain_points.requires_grad_(True)\n",
    "    \n",
    "    # 1. PDE Loss: ∇²u - f(x,y) = 0\n",
    "    u_domain = model(domain_points)\n",
    "    laplacian = compute_laplacian(u_domain, domain_points)\n",
    "    source = source_function(domain_points)\n",
    "    \n",
    "    pde_residual = laplacian - source\n",
    "    loss_pde = torch.mean(pde_residual**2)\n",
    "    \n",
    "    # 2. Boundary Loss: u = 0 on boundary\n",
    "    u_boundary = model(boundary_points)\n",
    "    bc_target = boundary_condition(boundary_points)\n",
    "    loss_boundary = torch.mean((u_boundary - bc_target)**2)\n",
    "    \n",
    "    # Total loss\n",
    "    total_loss = loss_pde + loss_boundary\n",
    "    \n",
    "    return {\n",
    "        'total': total_loss,\n",
    "        'pde': loss_pde,\n",
    "        'boundary': loss_boundary\n",
    "    }\n",
    "\n",
    "# Test loss computation\n",
    "with torch.no_grad():\n",
    "    losses = compute_losses(model, domain_points, boundary_points)\n",
    "    print(\"Initial losses:\")\n",
    "    for key, value in losses.items():\n",
    "        print(f\"  {key}: {value.item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, domain_points, boundary_points, \n",
    "                epochs=20000, lr=1e-3, print_every=1000):\n",
    "    \"\"\"Train the PINN model\"\"\"\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_history = []\n",
    "    \n",
    "    print(f\"Starting training for {epochs} epochs...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Compute losses\n",
    "        losses = compute_losses(model, domain_points, boundary_points)\n",
    "        total_loss = losses['total']\n",
    "        \n",
    "        # Backward pass\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Record losses\n",
    "        loss_history.append({\n",
    "            'epoch': epoch,\n",
    "            'total': total_loss.item(),\n",
    "            'pde': losses['pde'].item(),\n",
    "            'boundary': losses['boundary'].item()\n",
    "        })\n",
    "        \n",
    "        # Print progress\n",
    "        if (epoch + 1) % print_every == 0:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(f\"Epoch {epoch+1:5d}/{epochs} | \"\n",
    "                  f\"Total: {total_loss.item():.2e} | \"\n",
    "                  f\"PDE: {losses['pde'].item():.2e} | \"\n",
    "                  f\"BC: {losses['boundary'].item():.2e} | \"\n",
    "                  f\"Time: {elapsed_time:.1f}s\")\n",
    "            start_time = time.time()\n",
    "    \n",
    "    return loss_history\n",
    "\n",
    "# Train the model\n",
    "loss_history = train_model(model, domain_points, boundary_points, \n",
    "                          epochs=20000, lr=1e-3, print_every=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_history(loss_history):\n",
    "    \"\"\"Plot training loss history\"\"\"\n",
    "    epochs = [h['epoch'] for h in loss_history]\n",
    "    total_losses = [h['total'] for h in loss_history]\n",
    "    pde_losses = [h['pde'] for h in loss_history]\n",
    "    boundary_losses = [h['boundary'] for h in loss_history]\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(epochs, total_losses, 'b-', linewidth=2)\n",
    "    plt.yscale('log')\n",
    "    plt.title('Total Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(epochs, pde_losses, 'r-', linewidth=2)\n",
    "    plt.yscale('log')\n",
    "    plt.title('PDE Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(epochs, boundary_losses, 'g-', linewidth=2)\n",
    "    plt.yscale('log')\n",
    "    plt.title('Boundary Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot loss history\n",
    "plot_loss_history(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_solution(model, resolution=100):\n",
    "    \"\"\"Visualize the 2D solution as surface plots\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Create grid for visualization\n",
    "    x = torch.linspace(-1, 1, resolution)\n",
    "    y = torch.linspace(-1, 1, resolution)\n",
    "    X, Y = torch.meshgrid(x, y, indexing='ij')\n",
    "    \n",
    "    # Flatten for model prediction\n",
    "    xy_test = torch.stack([X.flatten(), Y.flatten()], dim=1).to(device)\n",
    "    \n",
    "    # Predict solution\n",
    "    with torch.no_grad():\n",
    "        u_pred = model(xy_test).cpu()\n",
    "    U_pred = u_pred.reshape(resolution, resolution)\n",
    "    \n",
    "    # Analytical solution\n",
    "    u_analytical = analytical_solution(xy_test).cpu()\n",
    "    U_analytical = u_analytical.reshape(resolution, resolution)\n",
    "    \n",
    "    # Compute errors\n",
    "    error = torch.abs(U_pred - U_analytical)\n",
    "    l2_error = torch.sqrt(torch.mean((U_pred - U_analytical)**2))\n",
    "    l2_relative = l2_error / torch.sqrt(torch.mean(U_analytical**2))\n",
    "    max_error = torch.max(error)\n",
    "    \n",
    "    # Convert to numpy for plotting\n",
    "    X_np, Y_np = X.numpy(), Y.numpy()\n",
    "    U_pred_np = U_pred.numpy()\n",
    "    U_analytical_np = U_analytical.numpy()\n",
    "    error_np = error.numpy()\n",
    "    \n",
    "    # Create 3D surface plots\n",
    "    fig = plt.figure(figsize=(18, 5))\n",
    "    \n",
    "    # PINN Solution\n",
    "    ax1 = fig.add_subplot(1, 3, 1, projection='3d')\n",
    "    surf1 = ax1.plot_surface(X_np, Y_np, U_pred_np, cmap='hot', alpha=0.8)\n",
    "    ax1.set_title('PINN Solution')\n",
    "    ax1.set_xlabel('x')\n",
    "    ax1.set_ylabel('y')\n",
    "    ax1.set_zlabel('u(x,y)')\n",
    "    \n",
    "    # Analytical Solution\n",
    "    ax2 = fig.add_subplot(1, 3, 2, projection='3d')\n",
    "    surf2 = ax2.plot_surface(X_np, Y_np, U_analytical_np, cmap='hot', alpha=0.8)\n",
    "    ax2.set_title('Analytical Solution')\n",
    "    ax2.set_xlabel('x')\n",
    "    ax2.set_ylabel('y')\n",
    "    ax2.set_zlabel('u(x,y)')\n",
    "    \n",
    "    # Error\n",
    "    ax3 = fig.add_subplot(1, 3, 3, projection='3d')\n",
    "    surf3 = ax3.plot_surface(X_np, Y_np, error_np, cmap='viridis', alpha=0.8)\n",
    "    ax3.set_title(f'Absolute Error\\nL2: {l2_error:.2e}')\n",
    "    ax3.set_xlabel('x')\n",
    "    ax3.set_ylabel('y')\n",
    "    ax3.set_zlabel('|Error|')\n",
    "    \n",
    "    plt.suptitle(\"2D Poisson Equation - PyTorch PINN Results\", fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "    \n",
    "    # Create contour plots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    # PINN Solution contour\n",
    "    im1 = axes[0].contourf(X_np, Y_np, U_pred_np, levels=20, cmap='hot')\n",
    "    axes[0].set_title('PINN Solution (Contour)')\n",
    "    axes[0].set_xlabel('x')\n",
    "    axes[0].set_ylabel('y')\n",
    "    plt.colorbar(im1, ax=axes[0])\n",
    "    \n",
    "    # Analytical Solution contour\n",
    "    im2 = axes[1].contourf(X_np, Y_np, U_analytical_np, levels=20, cmap='hot')\n",
    "    axes[1].set_title('Analytical Solution (Contour)')\n",
    "    axes[1].set_xlabel('x')\n",
    "    axes[1].set_ylabel('y')\n",
    "    plt.colorbar(im2, ax=axes[1])\n",
    "    \n",
    "    # Error contour\n",
    "    im3 = axes[2].contourf(X_np, Y_np, error_np, levels=20, cmap='viridis')\n",
    "    axes[2].set_title('Absolute Error (Contour)')\n",
    "    axes[2].set_xlabel('x')\n",
    "    axes[2].set_ylabel('y')\n",
    "    plt.colorbar(im3, ax=axes[2])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"L2 Absolute Error: {l2_error:.6e}\")\n",
    "    print(f\"L2 Relative Error: {l2_relative:.6e}\")\n",
    "    print(f\"Max Absolute Error: {max_error:.6e}\")\n",
    "    \n",
    "    return l2_error.item(), l2_relative.item(), max_error.item()\n",
    "\n",
    "# Visualize results\n",
    "l2_abs, l2_rel, max_abs = visualize_solution(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Detailed Analysis and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model at specific points\n",
    "model.eval()\n",
    "test_points = torch.tensor([\n",
    "    [0.0, 0.0],   # Center\n",
    "    [0.5, 0.5],   # First quadrant\n",
    "    [-0.5, 0.5],  # Second quadrant\n",
    "    [-0.5, -0.5], # Third quadrant\n",
    "    [0.5, -0.5],  # Fourth quadrant\n",
    "    [1.0, 0.0],   # Boundary point\n",
    "    [0.0, 1.0],   # Boundary point\n",
    "], device=device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    u_pred_test = model(test_points)\n",
    "    u_analytical_test = analytical_solution(test_points)\n",
    "\n",
    "print(\"\\n=== Point-wise Validation ===\")\n",
    "print(\"Point\\t\\tPINN\\t\\tAnalytical\\tError\")\n",
    "print(\"-\" * 60)\n",
    "for i, point in enumerate(test_points):\n",
    "    x, y = point[0].item(), point[1].item()\n",
    "    pred = u_pred_test[i].item()\n",
    "    true = u_analytical_test[i].item()\n",
    "    error = abs(pred - true)\n",
    "    print(f\"({x:5.1f}, {y:5.1f})\\t{pred:10.6f}\\t{true:10.6f}\\t{error:.2e}\")\n",
    "\n",
    "print(f\"\\n=== Final Model Statistics ===\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "print(f\"Training epochs: {len(loss_history)}\")\n",
    "print(f\"Final total loss: {loss_history[-1]['total']:.2e}\")\n",
    "print(f\"Final PDE loss: {loss_history[-1]['pde']:.2e}\")\n",
    "print(f\"Final boundary loss: {loss_history[-1]['boundary']:.2e}\")\n",
    "print(f\"L2 relative error: {l2_rel:.6e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Comparison with DeepXDE\n",
    "\n",
    "This PyTorch implementation demonstrates:\n",
    "\n",
    "### **Advantages of Pure PyTorch:**\n",
    "1. **Full Control**: Direct access to all components of the training process\n",
    "2. **Transparency**: Clear understanding of how gradients are computed\n",
    "3. **Flexibility**: Easy to modify loss functions, architectures, or training strategies\n",
    "4. **Debugging**: Ability to inspect intermediate computations\n",
    "5. **Custom Features**: Simple to add problem-specific enhancements\n",
    "\n",
    "### **Key Implementation Details:**\n",
    "- **Laplacian Computation**: Manual implementation using `torch.autograd.grad`\n",
    "- **Domain Sampling**: Custom functions for interior and boundary points\n",
    "- **Loss Construction**: Explicit combination of PDE and boundary losses\n",
    "- **Training Loop**: Standard PyTorch optimization with detailed monitoring\n",
    "\n",
    "The results should match the DeepXDE implementation while providing greater insight into the underlying mathematics and computation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}