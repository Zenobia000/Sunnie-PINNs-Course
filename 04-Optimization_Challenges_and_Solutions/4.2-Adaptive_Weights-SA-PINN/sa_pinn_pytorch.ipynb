{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Adaptive PINN (SA-PINN) - PyTorch Implementation\n",
    "\n",
    "This notebook demonstrates the Self-Adaptive PINN concept using PyTorch to solve a convection-diffusion equation with learnable loss weights.\n",
    "\n",
    "## Problem Definition:\n",
    "- **PDE**: $\\frac{\\partial u}{\\partial t} + \\beta \\frac{\\partial u}{\\partial x} = \\nu \\frac{\\partial^2 u}{\\partial x^2}$\n",
    "- **Domain**: $x \\in [-1, 1]$, $t \\in [0, 1]$\n",
    "- **Initial Condition**: $u(x, 0) = -\\sin(\\pi x)$\n",
    "- **Boundary Conditions**: $u(-1, t) = u(1, t) = 0$\n",
    "- **Parameters**: $\\beta = 1.0$, $\\nu = 0.01/\\pi$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Tuple, List\n",
    "\n",
    "# Set style for plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Problem Parameters and Domain Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define PDE parameters\n",
    "beta = 1.0  # Convection coefficient\n",
    "nu = 0.01 / np.pi  # Diffusion coefficient\n",
    "\n",
    "# Domain boundaries\n",
    "x_min, x_max = -1.0, 1.0\n",
    "t_min, t_max = 0.0, 1.0\n",
    "\n",
    "print(f\"Convection coefficient (beta): {beta}\")\n",
    "print(f\"Diffusion coefficient (nu): {nu:.6f}\")\n",
    "print(f\"Spatial domain: [{x_min}, {x_max}]\")\n",
    "print(f\"Time domain: [{t_min}, {t_max}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Generation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_domain_points(n_points: int) -> torch.Tensor:\n",
    "    \"\"\"Generate random points in the domain.\"\"\"\n",
    "    x = torch.rand(n_points, 1) * (x_max - x_min) + x_min\n",
    "    t = torch.rand(n_points, 1) * (t_max - t_min) + t_min\n",
    "    return torch.cat([x, t], dim=1).to(device)\n",
    "\n",
    "def generate_boundary_points(n_points: int) -> torch.Tensor:\n",
    "    \"\"\"Generate points on the spatial boundary.\"\"\"\n",
    "    # Left boundary: x = -1\n",
    "    n_left = n_points // 2\n",
    "    x_left = torch.full((n_left, 1), x_min)\n",
    "    t_left = torch.rand(n_left, 1) * (t_max - t_min) + t_min\n",
    "    \n",
    "    # Right boundary: x = 1\n",
    "    n_right = n_points - n_left\n",
    "    x_right = torch.full((n_right, 1), x_max)\n",
    "    t_right = torch.rand(n_right, 1) * (t_max - t_min) + t_min\n",
    "    \n",
    "    boundary_points = torch.cat([\n",
    "        torch.cat([x_left, t_left], dim=1),\n",
    "        torch.cat([x_right, t_right], dim=1)\n",
    "    ], dim=0)\n",
    "    \n",
    "    return boundary_points.to(device)\n",
    "\n",
    "def generate_initial_points(n_points: int) -> torch.Tensor:\n",
    "    \"\"\"Generate points on the initial condition (t = 0).\"\"\"\n",
    "    x = torch.rand(n_points, 1) * (x_max - x_min) + x_min\n",
    "    t = torch.zeros(n_points, 1)\n",
    "    return torch.cat([x, t], dim=1).to(device)\n",
    "\n",
    "def initial_condition(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Initial condition: u(x, 0) = -sin(π*x).\"\"\"\n",
    "    return -torch.sin(np.pi * x[:, 0:1])\n",
    "\n",
    "def boundary_condition(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Boundary condition: u(-1, t) = u(1, t) = 0.\"\"\"\n",
    "    return torch.zeros_like(x[:, 0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAPINN(nn.Module):\n",
    "    \"\"\"Self-Adaptive PINN with learnable loss weights.\"\"\"\n",
    "    \n",
    "    def __init__(self, layers: List[int] = [2, 32, 32, 32, 32, 1]):\n",
    "        super(SAPINN, self).__init__()\n",
    "        \n",
    "        # Neural network layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(len(layers) - 1):\n",
    "            self.layers.append(nn.Linear(layers[i], layers[i + 1]))\n",
    "        \n",
    "        # Initialize weights using Xavier normal\n",
    "        self.init_weights()\n",
    "        \n",
    "        # Learnable loss weights (SA-PINN key feature)\n",
    "        self.lambda_pde = nn.Parameter(torch.tensor(1.0, dtype=torch.float32))\n",
    "        self.lambda_bc = nn.Parameter(torch.tensor(1.0, dtype=torch.float32))\n",
    "        self.lambda_ic = nn.Parameter(torch.tensor(1.0, dtype=torch.float32))\n",
    "        \n",
    "        print(f\"SA-PINN initialized with {len(layers)} layers: {layers}\")\n",
    "        print(f\"Learnable weights initialized: λ_pde={self.lambda_pde.item():.3f}, λ_bc={self.lambda_bc.item():.3f}, λ_ic={self.lambda_ic.item():.3f}\")\n",
    "    \n",
    "    def init_weights(self):\n",
    "        \"\"\"Initialize network weights using Xavier normal initialization.\"\"\"\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.xavier_normal_(layer.weight)\n",
    "                nn.init.zeros_(layer.bias)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass through the network.\"\"\"\n",
    "        for i, layer in enumerate(self.layers[:-1]):\n",
    "            x = torch.tanh(layer(x))\n",
    "        # Final layer without activation\n",
    "        x = self.layers[-1](x)\n",
    "        return x\n",
    "    \n",
    "    def get_loss_weights(self) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Get current values of adaptive loss weights.\"\"\"\n",
    "        return self.lambda_pde, self.lambda_bc, self.lambda_ic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Physics-Informed Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_derivatives(u: torch.Tensor, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Compute first and second derivatives using automatic differentiation.\"\"\"\n",
    "    u_x = torch.autograd.grad(u, x, torch.ones_like(u), create_graph=True, retain_graph=True)[0]\n",
    "    u_t = u_x[:, 1:2]  # ∂u/∂t\n",
    "    u_x_spatial = u_x[:, 0:1]  # ∂u/∂x\n",
    "    \n",
    "    # Second derivative ∂²u/∂x²\n",
    "    u_xx = torch.autograd.grad(u_x_spatial, x, torch.ones_like(u_x_spatial), \n",
    "                              create_graph=True, retain_graph=True)[0][:, 0:1]\n",
    "    \n",
    "    return u_t, u_x_spatial, u_xx\n",
    "\n",
    "def pde_residual(model: SAPINN, x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Compute PDE residual: ∂u/∂t + β∂u/∂x - ν∂²u/∂x² = 0.\"\"\"\n",
    "    x.requires_grad_(True)\n",
    "    u = model(x)\n",
    "    \n",
    "    u_t, u_x, u_xx = compute_derivatives(u, x)\n",
    "    \n",
    "    # PDE: u_t + beta * u_x - nu * u_xx = 0\n",
    "    residual = u_t + beta * u_x - nu * u_xx\n",
    "    return residual\n",
    "\n",
    "def compute_losses(model: SAPINN, domain_points: torch.Tensor, \n",
    "                  boundary_points: torch.Tensor, initial_points: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Compute all loss components.\"\"\"\n",
    "    \n",
    "    # PDE loss\n",
    "    pde_pred = pde_residual(model, domain_points)\n",
    "    pde_loss = torch.mean(pde_pred**2)\n",
    "    \n",
    "    # Boundary condition loss\n",
    "    bc_pred = model(boundary_points)\n",
    "    bc_true = boundary_condition(boundary_points)\n",
    "    bc_loss = torch.mean((bc_pred - bc_true)**2)\n",
    "    \n",
    "    # Initial condition loss\n",
    "    ic_pred = model(initial_points)\n",
    "    ic_true = initial_condition(initial_points)\n",
    "    ic_loss = torch.mean((ic_pred - ic_true)**2)\n",
    "    \n",
    "    return pde_loss, bc_loss, ic_loss\n",
    "\n",
    "def compute_total_loss(model: SAPINN, domain_points: torch.Tensor,\n",
    "                      boundary_points: torch.Tensor, initial_points: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Compute weighted total loss using adaptive weights.\"\"\"\n",
    "    pde_loss, bc_loss, ic_loss = compute_losses(model, domain_points, boundary_points, initial_points)\n",
    "    \n",
    "    # Get adaptive weights\n",
    "    lambda_pde, lambda_bc, lambda_ic = model.get_loss_weights()\n",
    "    \n",
    "    # Weighted total loss\n",
    "    total_loss = lambda_pde * pde_loss + lambda_bc * bc_loss + lambda_ic * ic_loss\n",
    "    \n",
    "    return total_loss, pde_loss, bc_loss, ic_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Setup and Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = SAPINN([2, 32, 32, 32, 32, 1]).to(device)\n",
    "\n",
    "# Generate training data\n",
    "n_domain = 2540\n",
    "n_boundary = 80\n",
    "n_initial = 160\n",
    "\n",
    "domain_points = generate_domain_points(n_domain)\n",
    "boundary_points = generate_boundary_points(n_boundary)\n",
    "initial_points = generate_initial_points(n_initial)\n",
    "\n",
    "print(f\"Training data generated:\")\n",
    "print(f\"  Domain points: {domain_points.shape}\")\n",
    "print(f\"  Boundary points: {boundary_points.shape}\")\n",
    "print(f\"  Initial points: {initial_points.shape}\")\n",
    "\n",
    "# Optimizer (includes both network parameters and adaptive weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training parameters\n",
    "epochs = 25000\n",
    "log_interval = 1000\n",
    "\n",
    "# Storage for loss history and weight evolution\n",
    "loss_history = []\n",
    "weight_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "print(\"\\nStarting SA-PINN training...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Compute loss\n",
    "    total_loss, pde_loss, bc_loss, ic_loss = compute_total_loss(\n",
    "        model, domain_points, boundary_points, initial_points\n",
    "    )\n",
    "    \n",
    "    # Backward pass\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Store history\n",
    "    loss_history.append([\n",
    "        total_loss.item(), pde_loss.item(), bc_loss.item(), ic_loss.item()\n",
    "    ])\n",
    "    \n",
    "    # Store weight evolution\n",
    "    lambda_pde, lambda_bc, lambda_ic = model.get_loss_weights()\n",
    "    weight_history.append([\n",
    "        lambda_pde.item(), lambda_bc.item(), lambda_ic.item()\n",
    "    ])\n",
    "    \n",
    "    # Logging\n",
    "    if (epoch + 1) % log_interval == 0:\n",
    "        print(f\"Epoch {epoch + 1:5d}/{epochs} | \"\n",
    "              f\"Total: {total_loss.item():.2e} | \"\n",
    "              f\"PDE: {pde_loss.item():.2e} | \"\n",
    "              f\"BC: {bc_loss.item():.2e} | \"\n",
    "              f\"IC: {ic_loss.item():.2e}\")\n",
    "        print(f\"{'':17} | \"\n",
    "              f\"λ_pde: {lambda_pde.item():.3f} | \"\n",
    "              f\"λ_bc: {lambda_bc.item():.3f} | \"\n",
    "              f\"λ_ic: {lambda_ic.item():.3f}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "print(\"\\nTraining completed!\")\n",
    "\n",
    "# Convert to numpy for plotting\n",
    "loss_history = np.array(loss_history)\n",
    "weight_history = np.array(weight_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss history\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Total loss\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(loss_history[:, 0], 'b-', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Total Loss')\n",
    "plt.title('Total Weighted Loss')\n",
    "plt.yscale('log')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Individual loss components\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(loss_history[:, 1], 'r-', label='PDE Loss', linewidth=2)\n",
    "plt.plot(loss_history[:, 2], 'g-', label='BC Loss', linewidth=2)\n",
    "plt.plot(loss_history[:, 3], 'b-', label='IC Loss', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss Value')\n",
    "plt.title('Individual Loss Components')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Adaptive weights evolution\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(weight_history[:, 0], 'r-', label='$\\lambda_{PDE}$', linewidth=2)\n",
    "plt.plot(weight_history[:, 1], 'g-', label='$\\lambda_{BC}$', linewidth=2)\n",
    "plt.plot(weight_history[:, 2], 'b-', label='$\\lambda_{IC}$', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Weight Value')\n",
    "plt.title('Evolution of Adaptive Weights')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test data for visualization\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Create a grid for visualization\n",
    "    x_test = torch.linspace(x_min, x_max, 100)\n",
    "    t_test = torch.linspace(t_min, t_max, 50)\n",
    "    X_test, T_test = torch.meshgrid(x_test, t_test, indexing='ij')\n",
    "    \n",
    "    # Flatten and create input tensor\n",
    "    test_points = torch.stack([X_test.flatten(), T_test.flatten()], dim=1).to(device)\n",
    "    \n",
    "    # Get predictions\n",
    "    u_pred = model(test_points).cpu().numpy().reshape(X_test.shape)\n",
    "    \n",
    "    X_test_np = X_test.numpy()\n",
    "    T_test_np = T_test.numpy()\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# 2D solution plot\n",
    "plt.subplot(1, 3, 1)\n",
    "contour = plt.contourf(X_test_np, T_test_np, u_pred, levels=50, cmap='RdYlBu')\n",
    "plt.colorbar(contour)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('t')\n",
    "plt.title('SA-PINN Solution u(x,t)')\n",
    "\n",
    "# Solution at different times\n",
    "plt.subplot(1, 3, 2)\n",
    "time_indices = [0, 12, 24, 36, 49]  # Different time steps\n",
    "for i, t_idx in enumerate(time_indices):\n",
    "    plt.plot(x_test.numpy(), u_pred[:, t_idx], \n",
    "             label=f't = {T_test_np[0, t_idx]:.2f}', linewidth=2)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('u(x,t)')\n",
    "plt.title('Solution at Different Times')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 3D surface plot\n",
    "ax = plt.subplot(1, 3, 3, projection='3d')\n",
    "surf = ax.plot_surface(X_test_np, T_test_np, u_pred, \n",
    "                      cmap='RdYlBu', alpha=0.9)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('t')\n",
    "ax.set_zlabel('u(x,t)')\n",
    "ax.set_title('3D Solution Surface')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final Analysis and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final loss values and weights\n",
    "final_total_loss = loss_history[-1, 0]\n",
    "final_pde_loss = loss_history[-1, 1]\n",
    "final_bc_loss = loss_history[-1, 2]\n",
    "final_ic_loss = loss_history[-1, 3]\n",
    "\n",
    "final_lambda_pde = weight_history[-1, 0]\n",
    "final_lambda_bc = weight_history[-1, 1]\n",
    "final_lambda_ic = weight_history[-1, 2]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SA-PINN TRAINING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Problem: Convection-Diffusion Equation\")\n",
    "print(f\"Network Architecture: {[2, 32, 32, 32, 32, 1]}\")\n",
    "print(f\"Training Epochs: {epochs:,}\")\n",
    "print(f\"Training Points: {n_domain + n_boundary + n_initial:,}\")\n",
    "print()\n",
    "print(\"FINAL LOSS VALUES:\")\n",
    "print(f\"  Total Loss: {final_total_loss:.4e}\")\n",
    "print(f\"  PDE Loss:   {final_pde_loss:.4e}\")\n",
    "print(f\"  BC Loss:    {final_bc_loss:.4e}\")\n",
    "print(f\"  IC Loss:    {final_ic_loss:.4e}\")\n",
    "print()\n",
    "print(\"ADAPTIVE WEIGHT VALUES:\")\n",
    "print(f\"  λ_pde (Initial → Final): 1.000 → {final_lambda_pde:.3f}\")\n",
    "print(f\"  λ_bc  (Initial → Final): 1.000 → {final_lambda_bc:.3f}\")\n",
    "print(f\"  λ_ic  (Initial → Final): 1.000 → {final_lambda_ic:.3f}\")\n",
    "print()\n",
    "print(\"KEY FEATURES OF SA-PINN:\")\n",
    "print(\"✓ Automatic balance of loss components through learnable weights\")\n",
    "print(\"✓ No manual tuning of loss weight hyperparameters\")\n",
    "print(\"✓ Adaptive optimization balances competing physical constraints\")\n",
    "print(\"✓ Improved convergence for challenging PDEs with multiple scales\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}